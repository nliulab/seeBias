% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate_prediction.R
\name{evaluate_prediction_bin}
\alias{evaluate_prediction_bin}
\title{Evaluate algorithm fairness across patient subgroups based on predicted labels}
\usage{
evaluate_prediction_bin(
  y_pred,
  y_obs,
  y_pos = "1",
  sens_var,
  sens_var_ref = NULL
)
}
\arguments{
\item{y_pred}{A vector of predicted outcome labels. Should not contain
missing value.}

\item{y_obs}{A vector of observed binary outcome. Can be numeric, character
or factor. Should not contain missing value.}

\item{y_pos}{A character representing the positive class in \code{y_obs}. If
\code{y_obs} is a factor, by default \code{y_pos = levels(y_obs)[2]}. If
\code{y_obs} is numeric or character, by default \code{y_pos = "1"} for 0/1
encoding.}

\item{sens_var}{Sensitive variable(s). Must be categorical.}

\item{sens_var_ref}{Reference class(es) of sensitive variable(s). Default is the
default reference category in \code{sens_var}.}
}
\value{
Returns a data.frame of performance metrics evaluated within each
  sensitive group.
}
\description{
Evaluate algorithm fairness across patient subgroups based on predicted labels
}
